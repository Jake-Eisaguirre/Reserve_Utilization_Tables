---
title: "reserver_utl_p"
format: html
editor: source
---

```{r}
if (!require(librarian)){
  install.packages("librarian")  # Install 'librarian' package if it is not already installed
  library(librarian)  # Load the 'librarian' package
}

# librarian downloads, if not already downloaded, and reads in needed packages
librarian::shelf(tidyverse, here, DBI, odbc, padr)  # Load and ensure packages are installed: 'tidyverse', 'here', 'DBI', 'odbc', and 'padr'

```


```{r}
tryCatch({
    db_connection <- DBI::dbConnect(odbc::odbc(),
                             Driver="SnowflakeDSIIDriver",
                             Server="hawaiianair.west-us-2.azure.snowflakecomputing.com",
                             WAREHOUSE="DATA_LAKE_READER",
                             Database="ENTERPRISE",
                             UID= Sys.getenv("UID"),  # Get user ID from environment variable
                             authenticator = "externalbrowser")  # Authenticate using the browser
    print("Database Connected!")  # Print success message if database connection is successful
    },
    error=function(cond) {
            print("Unable to connect to Database.")  # Print error message if there is a failure to connect
})

# Set search_path
dbExecute(db_connection, "USE SCHEMA CREW_ANALYTICS")  # Set the schema to 'CREW_ANALYTICS'

# Query bid periods
q_bid_periods <- "SELECT DISTINCT BID_PERIOD FROM CT_MASTER_HISTORY ORDER BY BID_PERIOD DESC;"  # Define query to retrieve distinct bid periods
bid_periods <- dbGetQuery(db_connection, q_bid_periods) %>%  # Execute query and store results in 'bid_periods'
  filter(BID_PERIOD >= "2023-01",  # Filter for bid periods from January 2023 onwards
         BID_PERIOD <= "2024-10")  # Filter for bid periods before October 2024 - Depends when you build the initial table



```

```{r}


raw_date <- Sys.Date()  # Get the current system date and store it in 'raw_date'

utl_df <- data.frame()  # Create an empty data frame to store results

# Loop over each bid period
for (i in seq_along(bid_periods$BID_PERIOD)) { 
    
    # Query CT_MASTER_HISTORY for the current bid period
    q_master_history <- paste0("SELECT * FROM CT_MASTER_HISTORY WHERE BID_PERIOD = '", bid_periods$BID_PERIOD[i], "';")
    
    master_history_raw <- dbGetQuery(db_connection, q_master_history) %>%  # Execute query and store results
      mutate(UPDATE_TIME = as.character(UPDATE_TIME),  # Convert 'UPDATE_TIME' to character
             UPDATE_DATE = as.character(UPDATE_DATE))  # Convert 'UPDATE_DATE' to character
   
     # Filter and process data for pilots with ARC and SCR transaction codes
     pilot_ut_scr <- master_history_raw %>% 
       ungroup() %>% 
       filter(CREW_INDICATOR == "P") %>%  # Filter for pilots (P)
       filter(TRANSACTION_CODE %in% c("ARC", "SCR")) %>%  # Filter for ARC and SCR transaction codes
       mutate(update_dt = paste(UPDATE_DATE, UPDATE_TIME, sep = " ")) %>%  # Combine date and time
       group_by(CREW_ID, PAIRING_DATE, TRANSACTION_CODE) %>%  # Group by crew ID, pairing date, and transaction code
       mutate(temp_id = cur_group_id()) %>%  # Create a temporary group ID
       filter(!duplicated(temp_id)) %>%  # Remove duplicates based on temp ID
       ungroup() %>% 
       select(CREW_INDICATOR, CREW_ID, TRANSACTION_CODE,  # Select relevant columns
              PAIRING_DATE, TO_DATE, PAIRING_POSITION, BID_PERIOD, BASE)
     
     # Filter and process data for pilots with ASN transaction code
     pilot_ut_asn <- master_history_raw %>% 
       ungroup() %>% 
       filter(CREW_INDICATOR == "P") %>%  # Filter for pilots (P)
       filter(TRANSACTION_CODE %in% c("ASN")) %>%  # Filter for ASN transaction code
       mutate(update_dt = paste(UPDATE_DATE, UPDATE_TIME, sep = " ")) %>%  # Combine date and time
       group_by(CREW_ID, PAIRING_DATE, TRANSACTION_CODE) %>%  # Group by crew ID, pairing date, and transaction code
       mutate(temp_id = cur_group_id()) %>%  # Create a temporary group ID
       filter(!duplicated(temp_id)) %>%  # Remove duplicates based on temp ID
       ungroup() %>% 
       select(CREW_INDICATOR, CREW_ID, TRANSACTION_CODE, PAIRING_NO,  # Select relevant columns
              PAIRING_DATE, TO_DATE, PAIRING_POSITION, BID_PERIOD, BASE)
     
     # Query master schedule for the current bid period
     q_master_sched <- paste0("select CREW_ID, EFFECTIVE_FROM_DATE, EFFECTIVE_TO_DATE, EQUIPMENT, PAIRING_POSITION, BID_DATE,
                   UPDATE_DATE, UPDATE_TIME, BASE, BID_TYPE
                   from CT_MASTER_SCHEDULE WHERE BID_DATE = '", bid_periods$BID_PERIOD[i], "';")

     raw_ms <- dbGetQuery(db_connection, q_master_sched)  # Execute query and store results

     # Clean and process master schedule data
     clean_ms <- raw_ms %>% 
       mutate(update_dt = paste(UPDATE_DATE, UPDATE_TIME, sep = " ")) %>%  # Combine date and time
       group_by(CREW_ID, EFFECTIVE_FROM_DATE, EFFECTIVE_TO_DATE, PAIRING_POSITION) %>%  # Group by relevant columns
       filter(update_dt == max(update_dt)) %>%  # Filter for the latest update
       mutate(temp_id = cur_group_id()) %>%  # Create a temporary group ID
       filter(!duplicated(temp_id)) %>%  # Remove duplicates based on temp ID
       rename(BID_PERIOD = BID_DATE) %>%  # Rename 'BID_DATE' to 'BID_PERIOD'
       ungroup() %>% 
       select(CREW_ID, BID_PERIOD, PAIRING_POSITION, EQUIPMENT, BASE)  # Select relevant columns
     
     # Join pilot SCR data with master schedule data and filter for captain and first officer positions
     emp_hist_p_scr <- pilot_ut_scr %>% 
       left_join(clean_ms, by = c("CREW_ID", "BID_PERIOD", "PAIRING_POSITION", "BASE")) %>%  # Join data
       filter(PAIRING_POSITION %in% c("CA", "FO")) %>%  # Filter for captain and first officer positions
       select(!c(TO_DATE))  # Exclude the 'TO_DATE' column
     
     # Join pilot ASN data with master schedule data and filter for captain and first officer positions
     emp_hist_p_asn <- pilot_ut_asn %>% 
       inner_join(clean_ms, by = c("CREW_ID", "BID_PERIOD", "PAIRING_POSITION", "BASE")) %>%  # Join data
       filter(PAIRING_POSITION %in% c("CA", "FO"))  # Filter for captain and first officer positions
     
     # Process ASN data with multi-day pairings (double-day)
     asn_double <- emp_hist_p_asn %>%
       mutate(single = if_else(PAIRING_DATE == TO_DATE, 1, 0)) %>%  # Identify single-day pairings
       filter(single == 0) %>%  # Filter for multi-day pairings
       pivot_longer(cols = c("PAIRING_DATE", "TO_DATE"),  # Reshape data from wide to long format
                    values_to = "DATE") %>% 
       group_by(CREW_ID, EQUIPMENT, TRANSACTION_CODE, DATE) %>%  # Group by relevant columns
       mutate(temp_id = cur_group_id()) %>%  # Create a temporary group ID
       filter(!duplicated(temp_id)) %>%  # Remove duplicates based on temp ID
       ungroup() %>% 
       group_by(CREW_ID, TRANSACTION_CODE, EQUIPMENT, PAIRING_NO) %>%  # Group by relevant columns
       pad(by='DATE') %>%  # Pad missing dates in time series
       ungroup()%>% 
       rename(PAIRING_DATE = DATE) %>%  # Rename 'DATE' to 'PAIRING_DATE'
       select(!c(PAIRING_NO, single, name, temp_id))  %>%  # Exclude unnecessary columns
       fill(CREW_INDICATOR, CREW_ID, TRANSACTION_CODE, PAIRING_POSITION, BID_PERIOD, BASE, .direction = "down")  # Fill missing values downwards

     # Process ASN data with single-day pairings
     asn_single <- emp_hist_p_asn %>%
       mutate(single = if_else(PAIRING_DATE == TO_DATE, 1, 0)) %>%  # Identify single-day pairings
       filter(single == 1) %>%  # Filter for single-day pairings
       pivot_longer(cols = c("PAIRING_DATE", "TO_DATE"),  # Reshape data from wide to long format
                    values_to = "DATE") %>% 
       group_by(CREW_ID, EQUIPMENT, TRANSACTION_CODE, DATE) %>%  # Group by relevant columns
       mutate(temp_id = cur_group_id()) %>%  # Create a temporary group ID
       filter(!duplicated(temp_id)) %>%  # Remove duplicates based on temp ID
       ungroup() %>% 
       rename(PAIRING_DATE = DATE) %>%  # Rename 'DATE' to 'PAIRING_DATE'
       select(!c(PAIRING_NO, single, name, temp_id))  # Exclude unnecessary columns
     
     # Combine SCR, single-day ASN, and double-day ASN data
     utl_p <- rbind(emp_hist_p_scr, asn_single, asn_double) %>% 
       filter(PAIRING_DATE <= raw_date) %>%  # Filter for pairing dates up to current date
       mutate(TRANSACTION_CODE = if_else(TRANSACTION_CODE == "ACR", "SCR", TRANSACTION_CODE)) %>%  # Replace 'ACR' with 'SCR'
       filter(!EQUIPMENT == "33Y") %>%  # Exclude pairings with equipment type '33Y'
       ungroup() %>% 
       mutate(flag = if_else(PAIRING_DATE < 2024-04-31 & EQUIPMENT == "789", 1, 0)) %>%  # Flag certain pairings based on date and equipment
       filter(flag == 0) %>%  # Filter out flagged pairings
       select(!flag)  # Exclude the flag column
     
     # Combine current bid period data with the main data frame
     utl_df <- rbind(utl_p, utl_df)
     
     # Print progress message for the current bid period
     print(paste("Completed BID PERIOD:", bid_periods$BID_PERIOD[i]))
         
  }

```


```{r}

# Connect to the 'PLAYGROUND' database
tryCatch({
  db_connection_pg <- DBI::dbConnect(odbc::odbc(),
                                     Driver = "SnowflakeDSIIDriver",
                                     Server = "hawaiianair.west-us-2.azure.snowflakecomputing.com",
                                     WAREHOUSE = "DATA_LAKE_READER",
                                     Database = "PLAYGROUND",
                                     UID = "jacob.eisaguirre@hawaiianair.com",  # Use specified user ID
                                     authenticator = "externalbrowser")  # Authenticate using the browser
  print("Database Connected!")  # Print success message if database connection is successful
}, error = function(cond) {
  print("Unable to connect to Database.")  # Print error message if there is a failure to connect
})

# Set schema and retrieve data from 'AA_FINAL_PAIRING' table
dbExecute(db_connection_pg, "USE SCHEMA CREW_ANALYTICS")  # Set schema to 'CREW_ANALYTICS'

# Append the utilization data to the 'AA_RESERVE_UTILIZATION' table
dbAppendTable(db_connection_pg, "AA_RESERVE_UTILIZATION", utl_df)  # Append the contents of 'utl_df' to the database table



```